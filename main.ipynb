{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "212adbd6",
   "metadata": {},
   "source": [
    "# Franchir les frontières académiques : analyse des flux de mobilité des étudiants entrant dans l'enseignement supérieur\n",
    "\n",
    "Ce projet a été réalisé dans le cadre du cours de 2ème année de l'ENSAE \"Python pour la data science\" par Mathieu CAMBON, Charlotte HIECQUE et Elise MENSCH. \n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Contexte\n",
    "La plateforme Parcoursup affecte chaque année des milliers d'étudiants à une formation. Les formations sont nombreuses, et même si certaines ont le même objectif, chacune possède une identité propre pouvant inciter un étudiant à postuler à une formation plutôt qu'une autre, engendrant ainsi une certaine mobilité des étudiants. Pourtant, cette mobilité peut être contrainte par de nombreux facteurs. De plus, elle est inégalement répartie sur le territoire, avec certaines villes qui attirent un grand nombre de personnes tandis que d'autres engendrent une fuite des étudiants, qui se dirigent vers d'autres académies dans le cadre de leurs études supérieures. Il apparaît donc intéressant d'étudier la mobilité des étudiants lors de leur entrée en étude supérieure. Analyse de Parcoursup comme moteur de mobilité territoriale au lieu de l'orientation; \n",
    "\n",
    "### Problématique \n",
    "Quels sont les facteurs qui encouragent une mobilité lors de l'entrée dans l'éducation supérieure ? \n",
    "\n",
    "De manière plus précise, nous allons analyser les mécanismes suivants : \n",
    "- La géographie des flux : quels sont les académies qui attirent les étudiants et celles qui, au contraire les repoussent ?\n",
    "- La mobilité comme une stratégie pour accéder aux formations d'excellence;\n",
    "- L'offre de formation, notamment la sélectivité et le statut.\n",
    "\n",
    "### Données\n",
    "Pour effectuer cette analyse, nous avons principalement utilisé les données parcoursup en opendata sur data.gouv. A partir de cette base que nous avons nettoyé, nous avons créé de nouvelles données afin d'enrichir notre analyse. \n",
    "\n",
    "### Plan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e566b22",
   "metadata": {},
   "source": [
    "## Importation des bases de données et nettoyage\n",
    "\n",
    "### Importation des librairies nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a46f1af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4a66ff",
   "metadata": {},
   "source": [
    "### Nettoyage et enrichissement de la base de donnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64638486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chargement du fichier...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfunction\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m charger_donnees\n\u001b[32m      6\u001b[39m url_parcoursup2024 = \u001b[33m\"\u001b[39m\u001b[33mhttps://www.data.gouv.fr/api/1/datasets/r/1d916b7c-bd4c-4951-845a-70f7ad7c17db\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m df=\u001b[43mcharger_donnees\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl_parcoursup2024\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/Projet-python-data-science/function.py:181\u001b[39m, in \u001b[36mcharger_donnees\u001b[39m\u001b[34m(url)\u001b[39m\n\u001b[32m    178\u001b[39m df = nettoyage_base(df)\n\u001b[32m    179\u001b[39m df = enrichir_donnees(df)\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSuccès \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m lignes prêtes\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from function import charger_donnees\n",
    "\n",
    "url_parcoursup2024 = \"https://www.data.gouv.fr/api/1/datasets/r/1d916b7c-bd4c-4951-845a-70f7ad7c17db\"\n",
    "\n",
    "df=charger_donnees(url_parcoursup2024)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
